import streamlit as st
import requests
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime
import time
import json
from regional_analyzer import (RegionalAnalyzer,
                               REGION_CODES,
                               render_regional_dashboard)


class AlbamonAnalyzer:
    def __init__(self):
        self.base_url = 'https://bff-general.albamon.com'
        self.headers = {
            'Accept': '*/*',
            'User-Agent': 'job-site-monitor/1.0.0',
            'origin': 'https://www.albamon.com',
            'Content-Type': 'application/json',
            'cookie': (
                'ConditionId=25C99562-77E3-40EB-A750-DA27D2D03C54; '
                'ab.storage.deviceId.7a5f1472-069a-4372-8631-2f711442ee40'
                '=%7B%22g%22%3A%22efb20921-d9c8-43dd-3c27-8a1487d7d2c4%22'
                '%2C%22c%22%3A1756907811760%2C%22l%22%3A1756943038663%7D; '
                'AM_USER_UUID=e69544f8-bed4-4fc3-94c7-6efac20359f7; '
                'ab.storage.sessionId.7a5f1472-069a-4372-8631-2f711442ee40'
                '=%7B%22g%22%3A%22898147fc-a8ba-6427-1f60-647c10d3514e%22'
                '%2C%22e%22%3A1756945521947%2C%22c%22%3A1756943038661%2C'
                '%22l%22%3A1756943721947%7D'
            )
        }

    def search_jobs(self, page=1, size=200, search_period_type='ALL',
                    sort_type='RELATION'):
        request_body = {
            "pagination": {
                "page": int(page),
                "size": int(size)
            },
            "recruitListType": "SEARCH",
            "sortTabCondition": {
                "searchPeriodType": str(search_period_type),
                "sortType": str(sort_type)
            },
            "condition": {
                "areas": [],
                "employmentTypes": [],
                "excludeKeywords": [],
                "excludeBar": False,
                "excludeNegoAge": False,
                "excludeNegoWorkWeek": False,
                "excludeNegoWorkTime": False,
                "excludeNegoGender": False,
                "parts": [],
                "similarDongJoin": False,
                "workDayTypes": [],
                "workPeriodTypes": [],
                "workTimeTypes": [],
                "workWeekTypes": [],
                "endWorkTime": "",
                "startWorkTime": "",
                "includeKeyword": "",
                "excludeKeywordList": [],
                "age": 0,
                "genderType": "NONE",
                "moreThanEducation": False,
                "educationType": "ALL"
            },
            "extensionCondition": {
                "search": {
                    "keyword": "",
                    "featureCode": "",
                    "disableExceptedConditions": []
                }
            }
        }

        try:
            response = requests.post(
                f'{self.base_url}/recruit/search',
                json=request_body,
                headers=self.headers,
                timeout=30
            )
            response.raise_for_status()
            data = response.json()

            # ì˜¬ë°”ë¥¸ JSON ê²½ë¡œë¡œ ê³µê³  ë°ì´í„° ì¶”ì¶œ
            jobs = data.get('base', {}).get('normal', {}).get('collection', [])

            # ê¸°ì¡´ í˜•ì‹ì— ë§ì¶”ì–´ ë°˜í™˜ (í˜¸í™˜ì„± ìœ ì§€)
            return {
                'result': {'recruitList': jobs},
                'base': data.get('base', {}),
                '_debug_info': {
                    'original_job_count': len(jobs),
                    'json_structure': 'base.normal.collection'
                }
            }
        except requests.exceptions.RequestException as e:
            st.error(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None

    def categorize_job_posting(self, job):
        """
        ê³µê³  ì†ŒìŠ¤ ë° ìœ í˜• ë¶„ë¥˜
        """
        # ì†ŒìŠ¤ ë¶„ë¥˜
        if job.get('jobkoreaRecruitNo', 0) != 0:
            source = 'JOBKOREA'
        elif job.get('externalRecruitSite') == 'WN':
            source = 'WORKNET'
        else:
            source = 'ALBAMON'

        # ìœ ë£Œ/ë¬´ë£Œ ë¶„ë¥˜ (ALBAMON ê³µê³ ë§Œ)
        is_paid = False
        if source == 'ALBAMON':
            total_product_count = job.get(
                'paidService', {}).get('totalProductCount', 0)
            is_paid = total_product_count > 0

        return {
            'source': source,
            'is_paid': is_paid,
            'product_count': (
                job.get('paidService', {}).get('totalProductCount', 0)
                if source == 'ALBAMON' else None
            )
        }


    def find_source_range_efficient(self, search_period_type='ALL'):
        """
        ğŸš€ ê²½ê³„ ê¸°ë°˜ íš¨ìœ¨ì  íƒìƒ‰ - ìì‚¬>ì¡ì½”ë¦¬ì•„>ì›Œí¬ë„· ìˆœì„œë¥¼ í™œìš©í•œ ê°„ë‹¨í•œ ê²½ê³„ íƒì§€
        """
        search_start_time = time.time()
        total_requests = 0
        
        # ì „ì²´ ê³µê³  ìˆ˜ í™•ì¸
        first_response = self.search_jobs(1, 200, search_period_type)
        total_requests += 1
        
        if not first_response:
            return None, None, None, None, 0, {}, {}, 0

        total_count = (
            first_response.get('base', {})
            .get('pagination', {})
            .get('totalCount', 0)
        )
        max_pages = (total_count + 199) // 200 if total_count > 0 else 1

        st.info(f"ğŸš€ ê²½ê³„ ê¸°ë°˜ íƒìƒ‰: ì „ì²´ {total_count:,}ê°œ ê³µê³  ({max_pages}í˜ì´ì§€)")

        # 1ë‹¨ê³„: ì›Œí¬ë„· ê²½ê³„ ì°¾ê¸° (ëí˜ì´ì§€ë¶€í„°)
        st.info("ğŸ” ì›Œí¬ë„· ê²½ê³„ íƒìƒ‰ ì¤‘...")
        worknet_start = None
        worknet_end = None
        worknet_end_count = 0
        worknet_start_count = 0
        
        # ëí˜ì´ì§€ì—ì„œ ì›Œí¬ë„· í™•ì¸
        try:
            response = self.search_jobs(max_pages, 200, search_period_type)
            total_requests += 1
            if response:
                jobs = response.get('result', {}).get('recruitList', [])
                worknet_count = sum(1 for job in jobs if job.get('externalRecruitSite') == 'WN')
                if worknet_count > 0:
                    worknet_end = max_pages
                    worknet_end_count = worknet_count
                    st.info(f"ğŸ“ ì›Œí¬ë„· ë: {max_pages}í˜ì´ì§€ ({worknet_count}ê°œ)")
        except Exception as e:
            st.warning(f"ëí˜ì´ì§€ í™•ì¸ ì˜¤ë¥˜: {e}")

        # ì›Œí¬ë„·ì´ ìˆìœ¼ë©´ ì‹œì‘ì  ì°¾ê¸°
        if worknet_end:
            for i, page in enumerate(range(max_pages, 0, -1)):
                try:
                    # ì§„í–‰ ìƒí™© í‘œì‹œ
                    progress = (i + 1) / max_pages * 100
                    remaining_pages = max_pages - i
                    if i % 20 == 0 or page % 100 == 0:  # 20ë²ˆë§ˆë‹¤ ë˜ëŠ” 100í˜ì´ì§€ë§ˆë‹¤ í‘œì‹œ
                        st.info(f"ğŸ” ì›Œí¬ë„· íƒìƒ‰: í˜ì´ì§€ {page} í™•ì¸ ì¤‘ | ì§„í–‰ë¥ : {progress:.1f}% | ë‚¨ì€ í˜ì´ì§€: {remaining_pages}")
                    
                    response = self.search_jobs(page, 200, search_period_type)
                    total_requests += 1
                    
                    if not response:
                        continue

                    jobs = response.get('result', {}).get('recruitList', [])
                    if not jobs:
                        continue
                    
                    worknet_count = sum(1 for job in jobs if job.get('externalRecruitSite') == 'WN')
                    
                    if worknet_count > 0:
                        worknet_start = page
                        worknet_start_count = worknet_count
                    else:
                        # ì›Œí¬ë„·ì´ ì—†ëŠ” ì²« í˜ì´ì§€ ë°œê²¬ = ì›Œí¬ë„· ì‹œì‘ì  í™•ì •
                        st.info(f"âœ… ì›Œí¬ë„· ì‹œì‘ì  í™•ì •: {worknet_start}~{worknet_end}í˜ì´ì§€")
                        break
                        
                    time.sleep(0.002)
                    
                except Exception as e:
                    st.warning(f"í˜ì´ì§€ {page} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                    continue

        if worknet_start and worknet_end:
            st.success(f"âœ… ì›Œí¬ë„·: {worknet_start}~{worknet_end}í˜ì´ì§€")
        else:
            st.info("ğŸ“Š ì›Œí¬ë„· ê³µê³  ì—†ìŒ")

        # 2ë‹¨ê³„: ì¡ì½”ë¦¬ì•„ ê²½ê³„ ì°¾ê¸° (ì›Œí¬ë„· ì•ìª½ë¶€í„°)
        st.info("ğŸ” ì¡ì½”ë¦¬ì•„ ê²½ê³„ íƒìƒ‰ ì¤‘...")
        jobkorea_start = None
        jobkorea_end = None
        jobkorea_end_count = 0
        jobkorea_start_count = 0
        search_start_page = worknet_start - 1 if worknet_start else max_pages
        
        # ì›Œí¬ë„· ë°”ë¡œ ì• í˜ì´ì§€ì—ì„œ ì¡ì½”ë¦¬ì•„ í™•ì¸
        if search_start_page > 0:
            try:
                response = self.search_jobs(search_start_page, 200, search_period_type)
                total_requests += 1
                if response:
                    jobs = response.get('result', {}).get('recruitList', [])
                    jobkorea_count = sum(1 for job in jobs if job.get('jobkoreaRecruitNo', 0) != 0)
                    if jobkorea_count > 0:
                        jobkorea_end = search_start_page
                        jobkorea_end_count = jobkorea_count
                        st.info(f"ğŸ“ ì¡ì½”ë¦¬ì•„ ë: {search_start_page}í˜ì´ì§€ ({jobkorea_count}ê°œ)")
            except Exception as e:
                st.warning(f"ì¡ì½”ë¦¬ì•„ ëí˜ì´ì§€ í™•ì¸ ì˜¤ë¥˜: {e}")

        # ì¡ì½”ë¦¬ì•„ê°€ ìˆìœ¼ë©´ ì‹œì‘ì  ì°¾ê¸°
        if jobkorea_end:
            total_search_pages = search_start_page
            for i, page in enumerate(range(search_start_page, 0, -1)):
                try:
                    # ì§„í–‰ ìƒí™© í‘œì‹œ
                    progress = (i + 1) / total_search_pages * 100
                    remaining_pages = total_search_pages - i
                    if i % 20 == 0 or page % 100 == 0:  # 20ë²ˆë§ˆë‹¤ ë˜ëŠ” 100í˜ì´ì§€ë§ˆë‹¤ í‘œì‹œ
                        st.info(f"ğŸ” ì¡ì½”ë¦¬ì•„ íƒìƒ‰: í˜ì´ì§€ {page} í™•ì¸ ì¤‘ | ì§„í–‰ë¥ : {progress:.1f}% | ë‚¨ì€ í˜ì´ì§€: {remaining_pages}")
                    
                    response = self.search_jobs(page, 200, search_period_type)
                    total_requests += 1
                    
                    if not response:
                        continue

                    jobs = response.get('result', {}).get('recruitList', [])
                    if not jobs:
                        continue
                    
                    jobkorea_count = sum(1 for job in jobs if job.get('jobkoreaRecruitNo', 0) != 0)
                    
                    if jobkorea_count > 0:
                        jobkorea_start = page
                        jobkorea_start_count = jobkorea_count
                    else:
                        # ì¡ì½”ë¦¬ì•„ê°€ ì—†ëŠ” ì²« í˜ì´ì§€ ë°œê²¬ = ì¡ì½”ë¦¬ì•„ ì‹œì‘ì  í™•ì •
                        st.info(f"âœ… ì¡ì½”ë¦¬ì•„ ì‹œì‘ì  í™•ì •: {jobkorea_start}~{jobkorea_end}í˜ì´ì§€")
                        break
                        
                    time.sleep(0.002)
                    
                except Exception as e:
                    st.warning(f"í˜ì´ì§€ {page} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                    continue

        if jobkorea_start and jobkorea_end:
            st.success(f"âœ… ì¡ì½”ë¦¬ì•„: {jobkorea_start}~{jobkorea_end}í˜ì´ì§€")
        else:
            st.info("ğŸ“Š ì¡ì½”ë¦¬ì•„ ê³µê³  ì—†ìŒ")

        # 3ë‹¨ê³„: ì‹¤ì œ í™•ì¸í•œ ê°œìˆ˜ ê¸°ë°˜ ê³„ì‚° (ì¶”ê°€ ìš”ì²­ ì—†ì´)
        st.info("ğŸ” ê³µê³  ìˆ˜ ê³„ì‚° ì¤‘...")
        jobkorea_counts = {}
        worknet_counts = {}
        
        # ì¡ì½”ë¦¬ì•„ ê³µê³  ìˆ˜ ê³„ì‚° (ì‹¤ì œ í™•ì¸í•œ ê°œìˆ˜ ì‚¬ìš©)
        if jobkorea_start and jobkorea_end:
            total_pages = jobkorea_end - jobkorea_start + 1
            if total_pages == 1:
                # 1í˜ì´ì§€ë§Œ ìˆìœ¼ë©´ ì‹œì‘=ëì´ë¯€ë¡œ ì‹œì‘ í˜ì´ì§€ ê°œìˆ˜ ì‚¬ìš©
                jobkorea_counts[jobkorea_start] = jobkorea_start_count if jobkorea_start_count > 0 else jobkorea_end_count
            else:
                # ì—¬ëŸ¬ í˜ì´ì§€ë©´ ì‹œì‘/ëì€ ì‹¤ì œ ê°œìˆ˜, ì¤‘ê°„ì€ 200ê°œ
                for page in range(jobkorea_start, jobkorea_end + 1):
                    if page == jobkorea_start:
                        jobkorea_counts[page] = jobkorea_start_count  # ì‹¤ì œ í™•ì¸í•œ ì‹œì‘ í˜ì´ì§€ ê°œìˆ˜
                    elif page == jobkorea_end:
                        jobkorea_counts[page] = jobkorea_end_count  # ì‹¤ì œ í™•ì¸í•œ ë í˜ì´ì§€ ê°œìˆ˜
                    else:
                        jobkorea_counts[page] = 200  # ì¤‘ê°„ í˜ì´ì§€ëŠ” 200ê°œ (í•´ë‹¹ ì†ŒìŠ¤ë§Œ ìˆìŒ)
        
        # ì›Œí¬ë„· ê³µê³  ìˆ˜ ê³„ì‚° (ì‹¤ì œ í™•ì¸í•œ ê°œìˆ˜ ì‚¬ìš©)
        if worknet_start and worknet_end:
            total_pages = worknet_end - worknet_start + 1
            if total_pages == 1:
                # 1í˜ì´ì§€ë§Œ ìˆìœ¼ë©´ ì‹œì‘=ëì´ë¯€ë¡œ ì‹œì‘ í˜ì´ì§€ ê°œìˆ˜ ì‚¬ìš©
                worknet_counts[worknet_start] = worknet_start_count if worknet_start_count > 0 else worknet_end_count
            else:
                # ì—¬ëŸ¬ í˜ì´ì§€ë©´ ì‹œì‘/ëì€ ì‹¤ì œ ê°œìˆ˜, ì¤‘ê°„ì€ 200ê°œ
                for page in range(worknet_start, worknet_end + 1):
                    if page == worknet_start:
                        worknet_counts[page] = worknet_start_count  # ì‹¤ì œ í™•ì¸í•œ ì‹œì‘ í˜ì´ì§€ ê°œìˆ˜
                    elif page == worknet_end:
                        worknet_counts[page] = worknet_end_count  # ì‹¤ì œ í™•ì¸í•œ ë í˜ì´ì§€ ê°œìˆ˜
                    else:
                        worknet_counts[page] = 200  # ì¤‘ê°„ í˜ì´ì§€ëŠ” 200ê°œ (í•´ë‹¹ ì†ŒìŠ¤ë§Œ ìˆìŒ)

        # ê²€ìƒ‰ ì†Œìš”ì‹œê°„ ê³„ì‚°
        search_end_time = time.time()
        search_duration = search_end_time - search_start_time
        
        # ì‹¤ì œ ê³µê³  ìˆ˜ í•©ê³„ ê³„ì‚°
        total_jobkorea_count = sum(jobkorea_counts.values())
        total_worknet_count = sum(worknet_counts.values())

        # ê²°ê³¼ ë¡œê¹…
        if jobkorea_start and jobkorea_end:
            st.success(f"ğŸ“Š ì¡ì½”ë¦¬ì•„: {jobkorea_start}~{jobkorea_end}í˜ì´ì§€ (ì´ {total_jobkorea_count:,}ê°œ)")
        if worknet_start and worknet_end:
            st.success(f"ğŸ“Š ì›Œí¬ë„·: {worknet_start}~{worknet_end}í˜ì´ì§€ (ì´ {total_worknet_count:,}ê°œ)")
            
        st.success(f"âš¡ ê²½ê³„ íƒìƒ‰ ì™„ë£Œ: {search_duration:.2f}ì´ˆ, ì´ {total_requests}ë²ˆ ìš”ì²­")

        return jobkorea_start, jobkorea_end, worknet_start, worknet_end, total_count, jobkorea_counts, worknet_counts, search_duration

    def analyze_page_sources(self, start_page=1, end_page=10,
                             search_period_type='ALL'):
        """
        íŠ¹ì • í˜ì´ì§€ ë²”ìœ„ì˜ ê³µê³  ì†ŒìŠ¤ ë¶„ì„
        """
        page_results = []

        for page in range(start_page, end_page + 1):
            try:
                response = self.search_jobs(page, 200, search_period_type)
                if not response:
                    continue

                jobs = response.get('result', {}).get('recruitList', [])

                page_stats = {
                    'page': page,
                    'total_jobs': len(jobs),
                    'albamon': 0,
                    'jobkorea': 0,
                    'worknet': 0,
                    'sample_jobs': []
                }

                for job in jobs:
                    category = self.categorize_job_posting(job)
                    source = category['source']

                    if source == 'ALBAMON':
                        page_stats['albamon'] += 1
                    elif source == 'JOBKOREA':
                        page_stats['jobkorea'] += 1
                    elif source == 'WORKNET':
                        page_stats['worknet'] += 1

                # ê° í˜ì´ì§€ì—ì„œ ì²˜ìŒ 3ê°œ ê³µê³ ë§Œ ìƒ˜í”Œë¡œ ì €ì¥
                for job in jobs[:3]:
                    category = self.categorize_job_posting(job)
                    sample_info = {
                        'recruitNo': job.get('recruitNo'),
                        'title': job.get('recruitTitle', '')[:40] + '...',
                        'source': category['source'],
                        'is_paid': category['is_paid'],
                        'product_count': category['product_count'],
                        'jobkoreaRecruitNo': job.get('jobkoreaRecruitNo', 0),
                        'externalRecruitSite': job.get(
                            'externalRecruitSite', ''),
                    }
                    page_stats['sample_jobs'].append(sample_info)

                page_results.append(page_stats)
                time.sleep(0.1)

            except Exception as e:
                st.error(f"í˜ì´ì§€ {page} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        return page_results

    def comprehensive_job_analysis(self, search_period_type='ALL'):
        """
        íš¨ìœ¨ì ì¸ ë²”ìœ„ íƒìƒ‰ìœ¼ë¡œ ê³µê³  ë¶„ì„ - ë²”ìœ„ë¥¼ ì°¾ìœ¼ë©´ í•´ë‹¹ ë²”ìœ„ë§Œ ì •í™•íˆ ì¹´ìš´íŒ…
        """
        try:
            # íš¨ìœ¨ì ì¸ ë²”ìœ„ íƒìƒ‰ ì‚¬ìš©
            with st.spinner("ğŸ” íš¨ìœ¨ì  ë²”ìœ„ íƒìƒ‰ìœ¼ë¡œ ì¡ì½”ë¦¬ì•„/ì›Œí¬ë„· ë²”ìœ„ ê²€ìƒ‰ ì¤‘..."):
                result = self.find_source_range_efficient(search_period_type)
                    
            jobkorea_start, jobkorea_end, worknet_start, worknet_end, total_count, jobkorea_counts, worknet_counts, search_duration = result

            if total_count == 0:
                return {
                    'total_count': 0,
                    'albamon_count': 0,
                    'jobkorea_count': 0,
                    'worknet_count': 0,
                    'jobkorea_start_page': None,
                    'jobkorea_end_page': None,
                    'worknet_start_page': None,
                    'worknet_end_page': None,
                    'page_analysis': []
                }

            # ì²˜ìŒ 5í˜ì´ì§€ ìƒì„¸ ë¶„ì„ (ìƒ˜í”Œë§ìš©)
            page_results = self.analyze_page_sources(1, 5, search_period_type)

            # ğŸ¯ ì •í™•í•œ ê³µê³  ìˆ˜ ê³„ì‚° (ì‹¤ì œ í˜ì´ì§€ë³„ ì¹´ìš´íŠ¸ ê¸°ë°˜)
            # ì¡ì½”ë¦¬ì•„ ì‹¤ì œ ê³µê³  ìˆ˜
            jobkorea_count = sum(jobkorea_counts.values()) if jobkorea_counts else 0
            
            # ì›Œí¬ë„· ì‹¤ì œ ê³µê³  ìˆ˜  
            worknet_count = sum(worknet_counts.values()) if worknet_counts else 0
            
            # ìì‚¬ ê³µê³  ìˆ˜ = ì „ì²´ - ì¡ì½”ë¦¬ì•„ - ì›Œí¬ë„·
            albamon_count = total_count - jobkorea_count - worknet_count

            return {
                'total_count': total_count,
                'albamon_count': max(0, albamon_count),
                'jobkorea_count': max(0, jobkorea_count),
                'worknet_count': max(0, worknet_count),
                'jobkorea_start_page': jobkorea_start,
                'jobkorea_end_page': jobkorea_end,
                'worknet_start_page': worknet_start,
                'worknet_end_page': worknet_end,
                'page_analysis': page_results,
                'detailed_counts': {
                    'jobkorea_by_page': jobkorea_counts,
                    'worknet_by_page': worknet_counts
                },
                'search_duration': search_duration,
                'optimization_info': {
                    'jobkorea_range': f"{jobkorea_start}~{jobkorea_end}" if jobkorea_start and jobkorea_end else "ì—†ìŒ",
                    'worknet_range': f"{worknet_start}~{worknet_end}" if worknet_start and worknet_end else "ì—†ìŒ",
                    'accuracy': "í˜ì´ì§€ë³„ ì‹¤ì œ ê³µê³  ìˆ˜ ê¸°ë°˜ ì •í™• ê³„ì‚°",
                    'search_time': f"{search_duration:.2f}ì´ˆ"
                }
            }

        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None


def render_dashboard(results, title="ê³µê³  ë¶„ì„ ê²°ê³¼"):
    """ëŒ€ì‹œë³´ë“œ ë Œë”ë§ í•¨ìˆ˜"""
    if not results or results['total_count'] == 0:
        st.info("ë¶„ì„í•  ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.header(f"ğŸ” {title}")

    # ë©”íŠ¸ë¦­ ì¹´ë“œ
    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric(
            label="ğŸ“Š ì „ì²´ ê³µê³  ìˆ˜",
            value=f"{results['total_count']:,}ê°œ",
        )

    with col2:
        percentage = (
            results['albamon_count'] / results['total_count'] * 100
        )
        st.metric(
            label="ğŸ¢ ìì‚¬ ê³µê³ ",
            value=f"{results['albamon_count']:,}ê°œ",
            delta=f"{percentage:.1f}%"
        )

    with col3:
        percentage = (
            results['jobkorea_count'] / results['total_count'] * 100
        )
        st.metric(
            label="ğŸ’¼ ì¡ì½”ë¦¬ì•„ ê³µê³ ",
            value=f"{results['jobkorea_count']:,}ê°œ",
            delta=f"{percentage:.1f}%"
        )

    with col4:
        percentage = (
            results['worknet_count'] / results['total_count'] * 100
        )
        st.metric(
            label="ğŸ›ï¸ ì›Œí¬ë„· ê³µê³ ",
            value=f"{results['worknet_count']:,}ê°œ",
            delta=f"{percentage:.1f}%"
        )

    with col5:
        if results.get('search_duration'):
            st.metric(
                label="â±ï¸ ê²€ìƒ‰ ì‹œê°„",
                value=f"{results['search_duration']:.2f}ì´ˆ",
            )

    # í˜ì´ì§€ ë²”ìœ„ ì •ë³´ ê°•ì¡° í‘œì‹œ
    if (results.get('jobkorea_start_page') or results.get('worknet_start_page')):
        st.subheader("ğŸ¯ ê³µê³  ì†ŒìŠ¤ë³„ í˜ì´ì§€ ë²”ìœ„")
        col1, col2 = st.columns(2)

        with col1:
            if results.get('jobkorea_start_page'):
                start = results['jobkorea_start_page']
                end = results.get('jobkorea_end_page')
                if end:
                    range_text = f"{start}~{end}í˜ì´ì§€"
                else:
                    range_text = f"{start}í˜ì´ì§€ë¶€í„°"
                msg = f"ğŸ’¼ **ì¡ì½”ë¦¬ì•„ ê³µê³  ë²”ìœ„: {range_text}**"
                st.success(msg)
            else:
                st.info("ğŸ’¼ ì¡ì½”ë¦¬ì•„ ê³µê³  ì—†ìŒ")

        with col2:
            if results.get('worknet_start_page'):
                start = results['worknet_start_page']
                end = results.get('worknet_end_page')
                if end:
                    range_text = f"{start}~{end}í˜ì´ì§€"
                else:
                    range_text = f"{start}í˜ì´ì§€ë¶€í„°"
                msg = f"ğŸ›ï¸ **ì›Œí¬ë„· ê³µê³  ë²”ìœ„: {range_text}**"
                st.success(msg)
            else:
                st.info("ğŸ›ï¸ ì›Œí¬ë„· ê³µê³  ì—†ìŒ")

    # ì°¨íŠ¸ ì„¹ì…˜
    col1, col2 = st.columns(2)

    with col1:
        # íŒŒì´ ì°¨íŠ¸
        fig_pie = go.Figure(data=[go.Pie(
            labels=['ìì‚¬ ê³µê³ ', 'ì¡ì½”ë¦¬ì•„', 'ì›Œí¬ë„·'],
            values=[results['albamon_count'],
                    results['jobkorea_count'],
                    results['worknet_count']],
            hole=.3,
            marker_colors=['#FF6B6B', '#4ECDC4', '#45B7D1']
        )])
        fig_pie.update_layout(title="ê³µê³  ì†ŒìŠ¤ë³„ ë¶„í¬")
        st.plotly_chart(fig_pie, use_container_width=True)

    with col2:
        # ë°” ì°¨íŠ¸
        fig_bar = go.Figure(data=[
            go.Bar(
                x=['ìì‚¬ ê³µê³ ', 'ì¡ì½”ë¦¬ì•„', 'ì›Œí¬ë„·'],
                y=[results['albamon_count'],
                   results['jobkorea_count'],
                   results['worknet_count']],
                marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1']
            )
        ])
        fig_bar.update_layout(title="ê³µê³  ìˆ˜ ë¹„êµ", yaxis_title="ê³µê³  ìˆ˜")
        st.plotly_chart(fig_bar, use_container_width=True)

    # ìƒì„¸ ì •ë³´ í…Œì´ë¸”
    st.subheader("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    
    # í˜ì´ì§€ ë²”ìœ„ ì •ë³´ ìƒì„±
    jobkorea_range = "N/A"
    if results.get('jobkorea_start_page'):
        start = results['jobkorea_start_page']
        end = results.get('jobkorea_end_page')
        if end:
            jobkorea_range = f"{start}~{end}"
        else:
            jobkorea_range = f"{start}+"
            
    worknet_range = "N/A"
    if results.get('worknet_start_page'):
        start = results['worknet_start_page']
        end = results.get('worknet_end_page')
        if end:
            worknet_range = f"{start}~{end}"
        else:
            worknet_range = f"{start}+"
    
    detail_data = {
        'êµ¬ë¶„': ['ìì‚¬ ê³µê³ ', 'ì¡ì½”ë¦¬ì•„', 'ì›Œí¬ë„·', 'ì „ì²´'],
        'ê³µê³  ìˆ˜': [
            f"{results['albamon_count']:,}",
            f"{results['jobkorea_count']:,}",
            f"{results['worknet_count']:,}",
            f"{results['total_count']:,}"
        ],
        'ë¹„ìœ¨ (%)': [
            f"{results['albamon_count']/results['total_count']*100:.2f}",
            f"{results['jobkorea_count']/results['total_count']*100:.2f}",
            f"{results['worknet_count']/results['total_count']*100:.2f}",
            "100.00"
        ],
        'í˜ì´ì§€ ë²”ìœ„': [
            "1~ìì‚¬ë",
            jobkorea_range,
            worknet_range,
            f"1~{((results['total_count'] + 199) // 200)}"
        ]
    }

    df_detail = pd.DataFrame(detail_data)
    st.dataframe(df_detail, use_container_width=True)

    # ìµœì í™” ì •ë³´ í‘œì‹œ
    if results.get('optimization_info'):
        st.subheader("ğŸ¯ ê²€ìƒ‰ ìµœì í™” ê²°ê³¼")
        opt_info = results['optimization_info']
        col1, col2 = st.columns(2)
        
        with col1:
            st.info(f"**ì¡ì½”ë¦¬ì•„ ë²”ìœ„**: {opt_info.get('jobkorea_range', 'ì—†ìŒ')}")
        with col2:
            st.info(f"**ì›Œí¬ë„· ë²”ìœ„**: {opt_info.get('worknet_range', 'ì—†ìŒ')}")
            
        # ì •í™•ë„ ë° ì†Œìš”ì‹œê°„ ì •ë³´
        col1, col2 = st.columns(2)
        with col1:
            if opt_info.get('accuracy'):
                st.success(f"âœ… **ì •í™•ë„**: {opt_info['accuracy']}")
        with col2:
            if opt_info.get('search_time'):
                st.success(f"â±ï¸ **ê²€ìƒ‰ ì‹œê°„**: {opt_info['search_time']}")
            
        # ìƒì„¸ í˜ì´ì§€ë³„ ê³µê³  ìˆ˜ í‘œì‹œ
        if results.get('detailed_counts'):
            with st.expander("ğŸ“Š í˜ì´ì§€ë³„ ìƒì„¸ ê³µê³  ìˆ˜"):
                detail_counts = results['detailed_counts']
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if detail_counts.get('jobkorea_by_page'):
                        st.write("**ì¡ì½”ë¦¬ì•„ í˜ì´ì§€ë³„ ê³µê³  ìˆ˜:**")
                        for page, count in sorted(detail_counts['jobkorea_by_page'].items()):
                            st.write(f"  - í˜ì´ì§€ {page}: {count:,}ê°œ")
                    else:
                        st.write("**ì¡ì½”ë¦¬ì•„**: ê³µê³  ì—†ìŒ")
                        
                with col2:
                    if detail_counts.get('worknet_by_page'):
                        st.write("**ì›Œí¬ë„· í˜ì´ì§€ë³„ ê³µê³  ìˆ˜:**")
                        for page, count in sorted(detail_counts['worknet_by_page'].items()):
                            st.write(f"  - í˜ì´ì§€ {page}: {count:,}ê°œ")
                    else:
                        st.write("**ì›Œí¬ë„·**: ê³µê³  ì—†ìŒ")

    # JSON ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.download_button(
        label="ğŸ“¥ ê²°ê³¼ JSON ë‹¤ìš´ë¡œë“œ",
        data=json.dumps(results, indent=2, ensure_ascii=False),
        file_name=(
            f"albamon_analysis_"
            f"{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        ),
        mime="application/json"
    )


def main():
    st.set_page_config(
        page_title="ì±„ìš©ê³µê³  ëª¨ë‹ˆí„°ë§",
        page_icon="ğŸ“Š",
        layout="wide"
    )

    # í† í° ì¸ì¦ ì‹œìŠ¤í…œ
    SITE_TOKEN = "dkfqkcjsrnr1!"
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    
    # ì¸ì¦ë˜ì§€ ì•Šì€ ê²½ìš° í† í° ì…ë ¥ í™”ë©´ í‘œì‹œ
    if not st.session_state.authenticated:
        # ê°„ë‹¨í•œ ë‹¤í¬ ìŠ¤íƒ€ì¼
        st.markdown("""
        <style>
        .stApp {
            background-color: #1e1e1e;
        }
        .main .block-container {
            background-color: #2d2d2d;
            padding: 2rem;
            border-radius: 10px;
        }
        </style>
        """, unsafe_allow_html=True)
        
        st.title("ğŸ” ì‚¬ì´íŠ¸ ì ‘ê·¼ ì¸ì¦")
        st.subheader("í† í°ì„ ì…ë ¥í•˜ì—¬ ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ì„¸ìš”")
        
        # í† í° ì…ë ¥
        token_input = st.text_input(
            "ë³´ì•ˆ í† í°", 
            type="password", 
            key="token_input",
            placeholder="í† í°ì„ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        # í™•ì¸ ë²„íŠ¼
        if st.button("ì ‘ì†í•˜ê¸°", type="primary"):
            if token_input == SITE_TOKEN:
                st.session_state.authenticated = True
                st.success("ì¸ì¦ ì„±ê³µ!")
                st.rerun()
            elif token_input:
                st.error("ì˜ëª»ëœ í† í°ì…ë‹ˆë‹¤.")
        
        # Enter í‚¤ë¡œë„ ë™ì‘í•˜ë„ë¡
        if token_input == SITE_TOKEN:
            st.session_state.authenticated = True
            st.rerun()
            
        st.info("í† í°ì„ ì…ë ¥í•˜ê³  ì ‘ì†í•˜ê¸° ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”.")
        return
    
    # ì¸ì¦ëœ ì‚¬ìš©ìë§Œ ì‹¤ì œ ì»¨í…ì¸  í‘œì‹œ
    # ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼
    if st.button("ğŸšª ë¡œê·¸ì•„ì›ƒ", key="logout_btn"):
        st.session_state.authenticated = False
        st.rerun()

    # ì „ì²´ í™”ë©´ ë ˆì´ì•„ì›ƒì„ ìœ„í•œ CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
    st.markdown("""
    <style>
    .stColumn {
        width: 100% !important;
        flex: 1 1 0% !important;
        min-width: 0 !important;
    }
    .st-emotion-cache-1i94pul {
        width: 100% !important;
        flex: 1 1 0% !important;
    }
    .e1msl4mp1 {
        width: 100% !important;
    }
    .main .block-container {
        max-width: none !important;
        padding-left: 1rem !important;
        padding-right: 1rem !important;
    }
    div[data-testid="column"] {
        width: fit-content !important;
        flex: unset !important;
    }
    </style>
    """, unsafe_allow_html=True)

    st.title("ğŸ“Š ì±„ìš©ê³µê³  ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.markdown(
        "ì›Œí¬ë„·ê³¼ ì¡ì½”ë¦¬ì•„ ì—°ë™ ê³µê³  í˜„í™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤."
    )

    analyzer = AlbamonAnalyzer()
    regional_analyzer = RegionalAnalyzer()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ”§ ë¶„ì„ ì˜µì…˜")

        if st.button("ğŸ” ì „ì²´ ê³µê³  ë¶„ì„", type="primary"):
            st.session_state.run_analysis = True

        if st.button("ğŸ“… ì˜¤ëŠ˜ ê³µê³  ë¶„ì„"):
            st.session_state.check_today = True

        # ì§€ì—­ë³„ ë¶„ì„ ì„¤ì •
        st.markdown("#### ğŸ™ï¸ ì§€ì—­ë³„ ë¶„ì„ ì„¤ì •")
        selected_region_code = st.selectbox(
            "ì§€ì—­ ì„ íƒ",
            options=list(REGION_CODES.keys()),
            format_func=lambda x: f"{REGION_CODES[x]}",
            key="sidebar_region_select"
        )

        regional_period = st.selectbox(
            "ê¸°ê°„ ì„ íƒ",
            options=['ALL', 'TODAY'],
            format_func=lambda x: "ì „ì²´" if x == 'ALL' else "ì˜¤ëŠ˜",
            key="sidebar_period_select"
        )

        if st.button("ğŸ™ï¸ ì§€ì—­ë³„ ê³µê³  ë¶„ì„"):
            st.session_state.run_regional_analysis = True
            st.session_state.selected_region_code = selected_region_code
            st.session_state.selected_regional_period = regional_period

        st.markdown("---")
        st.markdown("### ğŸ“ ì •ë³´")
        st.info("""
        **ì •ë ¬ ìˆœì„œ**
        1. ìì‚¬ ê³µê³ 
        2. ì¡ì½”ë¦¬ì•„ ê³µê³ 
        3. ì›Œí¬ë„· ê³µê³  (ê³ ìš©24)

        **ğŸš€ íš¨ìœ¨ì  ë²”ìœ„ íƒìƒ‰ ë°©ë²•**
        
        **3ë‹¨ê³„ ìµœì í™” í”„ë¡œì„¸ìŠ¤**
        - ğŸ” 1ë‹¨ê³„: ë’¤ì—ì„œë¶€í„° ì›Œí¬ë„· ë²”ìœ„ íƒìƒ‰ ë° ë°œê²¬ ì‹œ ì¤‘ë‹¨
        - ğŸ” 2ë‹¨ê³„: ì›Œí¬ë„· ì•ìª½ì—ì„œ ì¡ì½”ë¦¬ì•„ ë²”ìœ„ íƒìƒ‰ ë° ë°œê²¬ ì‹œ ì¤‘ë‹¨  
        - ğŸ” 3ë‹¨ê³„: í™•ì •ëœ ë²”ìœ„ì—ì„œë§Œ ì •í™•í•œ ê³µê³  ìˆ˜ ê³„ì‚°
        
        **ì¡°ê±´**
        - ğŸ¯ **ì¡ì½”ë¦¬ì•„**: jobkoreaRecruitNo != 0
        - ğŸ¯ **ì›Œí¬ë„·**: externalRecruitSite == 'WN'
        - ğŸ¯ **ìì‚¬**: ë‚˜ë¨¸ì§€ ëª¨ë“  ê³µê³ 
        
        **ì¥ì **
        - âœ… ë¶ˆí•„ìš”í•œ ì „ì²´ íƒìƒ‰ ì œê±°ë¡œ ì†ë„ í–¥ìƒ
        - âœ… ë²”ìœ„ í™•ì • í›„ ì •í™•í•œ ì¹´ìš´íŒ…
        - âœ… ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© í‘œì‹œ
        """)

    # ì „ì²´ ê³µê³  ë¶„ì„
    if (hasattr(st.session_state, 'run_analysis') and
            st.session_state.run_analysis):
        results = analyzer.comprehensive_job_analysis('ALL')
        if results:
            render_dashboard(results, "ì „ì²´ ê³µê³  ë¶„ì„ ê²°ê³¼")
        st.session_state.run_analysis = False

    # ì˜¤ëŠ˜ ê³µê³  ë¶„ì„
    if (hasattr(st.session_state, 'check_today') and
            st.session_state.check_today):
        results = analyzer.comprehensive_job_analysis('TODAY')
        if results:
            render_dashboard(results, "ì˜¤ëŠ˜ ë“±ë¡ëœ ê³µê³  ë¶„ì„ ê²°ê³¼")
        st.session_state.check_today = False

    # ì§€ì—­ë³„ ë¶„ì„
    if (hasattr(st.session_state, 'run_regional_analysis') and
            st.session_state.run_regional_analysis):
        region_code = st.session_state.selected_region_code
        region_name = REGION_CODES[region_code]
        period = st.session_state.selected_regional_period

        results = regional_analyzer.analyze_regional_jobs(
            region_code, region_name, period, max_pages=3
        )
        if results:
            render_regional_dashboard(results)
        st.session_state.run_regional_analysis = False

    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
    <small>
    ì±„ìš©ê³µê³  APIë¥¼ í™œìš©í•œ ê³µê³  ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ | ë°ì´í„° ì—…ë°ì´íŠ¸: ì‹¤ì‹œê°„
    </small>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()